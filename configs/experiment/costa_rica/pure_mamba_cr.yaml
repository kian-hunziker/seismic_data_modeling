# @package _global_

defaults:
  - /trainer: default
  - /loader: default
  - /dataset: cr_small_long_seq
  - /task: classification
  - /optimizer: adamw_mamba
  - /scheduler: cosine_warmup
  - /model: pure_mamba

experiment_name: pure_mamba_cr

model:
  d_model: 64
  n_layers: 16
  is_complex: True

train:
  monitor: val/loss
  mode: min

dataset:
  sample_len: 131072
  downsample: 100
  bits: 8

encoder:
  _name_: embedding

decoder:
  _name_: linear

loader:
  batch_size: 4

scheduler:
  num_warmup_steps: 1000
  num_training_steps: 10000

trainer:
  max_steps: 10000
  max_epochs: 10000
  gradient_clip_val: 1.0
