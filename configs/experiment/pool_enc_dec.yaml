# @package _global_

defaults:
  - /trainer: default
  - /loader: default
  - /dataset: cr_enc_dec
  - /task: regression
  - /optimizer: adamw
  - /scheduler: plateau
  - /model: identity

experiment_name: pool_enc_dec_transformer

train:
  #ckpt_path: wandb_logs/MA/2024-09-06__16_06_55
  monitor: val/loss
  mode: min

task:
  metrics:
    - log_mse
    - mse

encoder:
  _name_: pool
  hidden_dim: 128
  pool: 16

#decoder:
#  _name_: s4-decoder
#  d_model: 64
#  n_blocks: 5

decoder:
  _name_: transformer
  d_model: 64
  seq_len: 1024
  latent_dim: 64
  regression: True
  vocab_size: 256
  nhead: 8
  dim_feedforward: 128
  num_layers: 4

loader:
  batch_size: 16

scheduler:
  patience: 40

trainer:
  max_steps: 50000
  max_epochs: 50000
  log_every_n_steps: 1
  #gradient_clip_val: 1.0
  precision: 32

dataset:
  data_dir: dataloaders/data/costa_rica/small_subset
  sample_len: 1024
  bits: 0
